{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'conv1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m modules_to_list \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodules_to_fuse()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# This will fuse BatchNorm weights into the preceding Conv\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m fused_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mao\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuse_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnet18\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodules_to_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Assigning qconfigs\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_quantize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeQuantize\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\ao\\quantization\\fuse_modules.py:193\u001b[0m, in \u001b[0;36mfuse_modules\u001b[1;34m(model, modules_to_fuse, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfuse_modules\u001b[39m(\n\u001b[0;32m    133\u001b[0m     model,\n\u001b[0;32m    134\u001b[0m     modules_to_fuse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m     fuse_custom_config_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    138\u001b[0m ):\n\u001b[0;32m    139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Fuse a list of modules into a single module.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    Fuses only the following sequence of modules:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m \n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fuse_modules\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodules_to_fuse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_qat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuser_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuser_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuse_custom_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuse_custom_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\ao\\quantization\\fuse_modules.py:126\u001b[0m, in \u001b[0;36m_fuse_modules\u001b[1;34m(model, modules_to_fuse, is_qat, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# Handle case of modules_to_fuse being a list of lists\u001b[39;00m\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module_list \u001b[38;5;129;01min\u001b[39;00m modules_to_fuse:\n\u001b[1;32m--> 126\u001b[0m         \u001b[43m_fuse_modules_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_qat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuser_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuse_custom_config_dict\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\ao\\quantization\\fuse_modules.py:97\u001b[0m, in \u001b[0;36m_fuse_modules_helper\u001b[1;34m(model, modules_to_fuse, is_qat, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[0;32m     95\u001b[0m mod_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m modules_to_fuse:\n\u001b[1;32m---> 97\u001b[0m     mod_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Fuse list of modules\u001b[39;00m\n\u001b[0;32m    100\u001b[0m new_mod_list \u001b[38;5;241m=\u001b[39m fuser_func(mod_list, is_qat, additional_fuser_method_mapping)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\ao\\quantization\\fuse_modules.py:28\u001b[0m, in \u001b[0;36m_get_module\u001b[1;34m(model, submodule_key)\u001b[0m\n\u001b[0;32m     26\u001b[0m cur_mod \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[1;32m---> 28\u001b[0m     cur_mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(cur_mod, s)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cur_mod\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'conv1'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from resfile.resnet import resnet18\n",
    "from evaluate import evaluate\n",
    "model= None\n",
    "model = resnet18()\n",
    "#print(model)\n",
    "modules_to_list = model.modules_to_fuse()\n",
    "# This will fuse BatchNorm weights into the preceding Conv\n",
    "fused_model = torch.ao.quantization.fuse_modules(resnet18, modules_to_list)\n",
    "\n",
    "# Assigning qconfigs\n",
    "from torch.ao.quantization.fake_quantize import FakeQuantize\n",
    "activation_qconfig = FakeQuantize.with_args(\n",
    "    observer=torch.ao.quantization.observer.HistogramObserver.with_args(\n",
    "        quant_min=0,\n",
    "        quant_max=255,\n",
    "        dtype=torch.quint8,\n",
    "        qscheme=torch.per_tensor_affine,\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_qconfig = FakeQuantize.with_args(\n",
    "    observer=torch.ao.quantization.observer.PerChannelMinMaxObserver.with_args(\n",
    "        quant_min=-128,\n",
    "        quant_max=127,\n",
    "        dtype=torch.qint8,\n",
    "        qscheme=torch.per_channel_symmetric,\n",
    "    )\n",
    ")\n",
    "\n",
    "qconfig = torch.quantization.QConfig(activation=activation_qconfig,\n",
    "                                      weight=weight_qconfig)\n",
    "fused_model.qconfig = qconfig\n",
    "\n",
    "#  Prepare for fake-quant\n",
    "fused_model.train()\n",
    "fake_quant_model = torch.ao.quantization.prepare_qat(fused_model)\n",
    "\n",
    "print(\"\\nFused Model\")\n",
    "evaluate(fused_model, 'cpu')\n",
    "\n",
    "print(\"\\nFake quant - PTQ\")\n",
    "evaluate(fake_quant_model, 'cpu')\n",
    "\n",
    "fake_quant_model.apply(torch.ao.quantization.fake_quantize.disable_observer)\n",
    "\n",
    "print(\"\\nFake quant - post-PTQ\")\n",
    "evaluate(fake_quant_model, 'cpu')\n",
    "\n",
    "converted_model = torch.ao.quantization.convert(fake_quant_model)\n",
    "\n",
    "print(\"\\nConverted model\")\n",
    "evaluate(converted_model, 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
